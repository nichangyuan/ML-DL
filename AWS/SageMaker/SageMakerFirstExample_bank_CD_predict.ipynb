{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  To prepare the data, train the ML model, and deploy it, you will need to import some libraries and define a few environment variables in your Jupyter notebook environment. Copy the following code into the code cell in your instance and select Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-west-1 region. You will use the 632365934929.dkr.ecr.us-west-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-1': '632365934929.dkr.ecr.us-west-1.amazonaws.com/xgboost:latest',\n",
    "              'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an S3 bucket that will store your data for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'chuck-s3-bucket-name' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the data to your Amazon SageMaker instance and load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "  print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "  print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "  model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41188 entries, 0 to 41187\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype\n",
      "---  ------                         --------------  -----\n",
      " 0   age                            41188 non-null  int64\n",
      " 1   campaign                       41188 non-null  int64\n",
      " 2   pdays                          41188 non-null  int64\n",
      " 3   previous                       41188 non-null  int64\n",
      " 4   no_previous_contact            41188 non-null  int64\n",
      " 5   not_working                    41188 non-null  int64\n",
      " 6   job_admin.                     41188 non-null  int64\n",
      " 7   job_blue-collar                41188 non-null  int64\n",
      " 8   job_entrepreneur               41188 non-null  int64\n",
      " 9   job_housemaid                  41188 non-null  int64\n",
      " 10  job_management                 41188 non-null  int64\n",
      " 11  job_retired                    41188 non-null  int64\n",
      " 12  job_self-employed              41188 non-null  int64\n",
      " 13  job_services                   41188 non-null  int64\n",
      " 14  job_student                    41188 non-null  int64\n",
      " 15  job_technician                 41188 non-null  int64\n",
      " 16  job_unemployed                 41188 non-null  int64\n",
      " 17  job_unknown                    41188 non-null  int64\n",
      " 18  marital_divorced               41188 non-null  int64\n",
      " 19  marital_married                41188 non-null  int64\n",
      " 20  marital_single                 41188 non-null  int64\n",
      " 21  marital_unknown                41188 non-null  int64\n",
      " 22  education_basic.4y             41188 non-null  int64\n",
      " 23  education_basic.6y             41188 non-null  int64\n",
      " 24  education_basic.9y             41188 non-null  int64\n",
      " 25  education_high.school          41188 non-null  int64\n",
      " 26  education_illiterate           41188 non-null  int64\n",
      " 27  education_professional.course  41188 non-null  int64\n",
      " 28  education_university.degree    41188 non-null  int64\n",
      " 29  education_unknown              41188 non-null  int64\n",
      " 30  default_no                     41188 non-null  int64\n",
      " 31  default_unknown                41188 non-null  int64\n",
      " 32  default_yes                    41188 non-null  int64\n",
      " 33  housing_no                     41188 non-null  int64\n",
      " 34  housing_unknown                41188 non-null  int64\n",
      " 35  housing_yes                    41188 non-null  int64\n",
      " 36  loan_no                        41188 non-null  int64\n",
      " 37  loan_unknown                   41188 non-null  int64\n",
      " 38  loan_yes                       41188 non-null  int64\n",
      " 39  contact_cellular               41188 non-null  int64\n",
      " 40  contact_telephone              41188 non-null  int64\n",
      " 41  month_apr                      41188 non-null  int64\n",
      " 42  month_aug                      41188 non-null  int64\n",
      " 43  month_dec                      41188 non-null  int64\n",
      " 44  month_jul                      41188 non-null  int64\n",
      " 45  month_jun                      41188 non-null  int64\n",
      " 46  month_mar                      41188 non-null  int64\n",
      " 47  month_may                      41188 non-null  int64\n",
      " 48  month_nov                      41188 non-null  int64\n",
      " 49  month_oct                      41188 non-null  int64\n",
      " 50  month_sep                      41188 non-null  int64\n",
      " 51  day_of_week_fri                41188 non-null  int64\n",
      " 52  day_of_week_mon                41188 non-null  int64\n",
      " 53  day_of_week_thu                41188 non-null  int64\n",
      " 54  day_of_week_tue                41188 non-null  int64\n",
      " 55  day_of_week_wed                41188 non-null  int64\n",
      " 56  poutcome_failure               41188 non-null  int64\n",
      " 57  poutcome_nonexistent           41188 non-null  int64\n",
      " 58  poutcome_success               41188 non-null  int64\n",
      " 59  y_no                           41188 non-null  int64\n",
      " 60  y_yes                          41188 non-null  int64\n",
      "dtypes: int64(61)\n",
      "memory usage: 19.5 MB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>y_no</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.02406</td>\n",
       "      <td>2.567593</td>\n",
       "      <td>962.475454</td>\n",
       "      <td>0.172963</td>\n",
       "      <td>0.963217</td>\n",
       "      <td>0.087623</td>\n",
       "      <td>0.253035</td>\n",
       "      <td>0.224677</td>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.025736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.206711</td>\n",
       "      <td>0.209357</td>\n",
       "      <td>0.196416</td>\n",
       "      <td>0.197485</td>\n",
       "      <td>0.103234</td>\n",
       "      <td>0.863431</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.887346</td>\n",
       "      <td>0.112654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.42125</td>\n",
       "      <td>2.770014</td>\n",
       "      <td>186.910907</td>\n",
       "      <td>0.494901</td>\n",
       "      <td>0.188230</td>\n",
       "      <td>0.282749</td>\n",
       "      <td>0.434756</td>\n",
       "      <td>0.417375</td>\n",
       "      <td>0.184665</td>\n",
       "      <td>0.158348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392330</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>0.406855</td>\n",
       "      <td>0.397292</td>\n",
       "      <td>0.398106</td>\n",
       "      <td>0.304268</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>0.179512</td>\n",
       "      <td>0.316173</td>\n",
       "      <td>0.316173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.00000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               age      campaign         pdays      previous  \\\n",
       "count  41188.00000  41188.000000  41188.000000  41188.000000   \n",
       "mean      40.02406      2.567593    962.475454      0.172963   \n",
       "std       10.42125      2.770014    186.910907      0.494901   \n",
       "min       17.00000      1.000000      0.000000      0.000000   \n",
       "25%       32.00000      1.000000    999.000000      0.000000   \n",
       "50%       38.00000      2.000000    999.000000      0.000000   \n",
       "75%       47.00000      3.000000    999.000000      0.000000   \n",
       "max       98.00000     56.000000    999.000000      7.000000   \n",
       "\n",
       "       no_previous_contact   not_working    job_admin.  job_blue-collar  \\\n",
       "count         41188.000000  41188.000000  41188.000000     41188.000000   \n",
       "mean              0.963217      0.087623      0.253035         0.224677   \n",
       "std               0.188230      0.282749      0.434756         0.417375   \n",
       "min               0.000000      0.000000      0.000000         0.000000   \n",
       "25%               1.000000      0.000000      0.000000         0.000000   \n",
       "50%               1.000000      0.000000      0.000000         0.000000   \n",
       "75%               1.000000      0.000000      1.000000         0.000000   \n",
       "max               1.000000      1.000000      1.000000         1.000000   \n",
       "\n",
       "       job_entrepreneur  job_housemaid  ...  day_of_week_fri  day_of_week_mon  \\\n",
       "count      41188.000000   41188.000000  ...     41188.000000     41188.000000   \n",
       "mean           0.035350       0.025736  ...         0.190031         0.206711   \n",
       "std            0.184665       0.158348  ...         0.392330         0.404951   \n",
       "min            0.000000       0.000000  ...         0.000000         0.000000   \n",
       "25%            0.000000       0.000000  ...         0.000000         0.000000   \n",
       "50%            0.000000       0.000000  ...         0.000000         0.000000   \n",
       "75%            0.000000       0.000000  ...         0.000000         0.000000   \n",
       "max            1.000000       1.000000  ...         1.000000         1.000000   \n",
       "\n",
       "       day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "count     41188.000000     41188.000000     41188.000000      41188.000000   \n",
       "mean          0.209357         0.196416         0.197485          0.103234   \n",
       "std           0.406855         0.397292         0.398106          0.304268   \n",
       "min           0.000000         0.000000         0.000000          0.000000   \n",
       "25%           0.000000         0.000000         0.000000          0.000000   \n",
       "50%           0.000000         0.000000         0.000000          0.000000   \n",
       "75%           0.000000         0.000000         0.000000          0.000000   \n",
       "max           1.000000         1.000000         1.000000          1.000000   \n",
       "\n",
       "       poutcome_nonexistent  poutcome_success          y_no         y_yes  \n",
       "count          41188.000000      41188.000000  41188.000000  41188.000000  \n",
       "mean               0.863431          0.033335      0.887346      0.112654  \n",
       "std                0.343396          0.179512      0.316173      0.316173  \n",
       "min                0.000000          0.000000      0.000000      0.000000  \n",
       "25%                1.000000          0.000000      1.000000      0.000000  \n",
       "50%                1.000000          0.000000      1.000000      0.000000  \n",
       "75%                1.000000          0.000000      1.000000      0.000000  \n",
       "max                1.000000          1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training data (70% of customers) will be used during the model training loop. We will use gradient-based optimization to iteratively refine the model parameters. \n",
    "### The test data (remaining 30% of customers) will be used to evaluate the performance of the model, and measure how well the trained model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use an Amazon SageMaker pre-built XGBoost model, you will need to reformat the header and first column of the training data and load the data from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, you need to set up the Amazon SageMaker session, create an instance of the XGBoost model (an estimator), and define the model’s hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[my_region],role, train_instance_count=1, train_instance_type='ml.m4.xlarge',output_path='s3://{}/{}/output'.format(bucket_name, prefix),sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='binary:logistic',num_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the data loaded and the XGBoost estimator set up, train the model using gradient optimization on a ml.m4.xlarge instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-15 23:04:45 Starting - Starting the training job...\n",
      "2020-10-15 23:04:47 Starting - Launching requested ML instances......\n",
      "2020-10-15 23:06:06 Starting - Preparing the instances for training......\n",
      "2020-10-15 23:07:15 Downloading - Downloading input data\n",
      "2020-10-15 23:07:15 Training - Downloading the training image...\n",
      "2020-10-15 23:07:40 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-10-15:23:07:35:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-10-15:23:07:35:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2020-10-15:23:07:35:INFO] File size need to be processed in the node: 3.38mb. Available memory size in the node: 8480.28mb\u001b[0m\n",
      "\u001b[34m[2020-10-15:23:07:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:07:35] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:07:35] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.100482\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.099858\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.099476\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.099025\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.099476\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.099372\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.09906\u001b[0m\n",
      "\u001b[34m[23:07:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.099025\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.099164\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.098852\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.098574\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.098609\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.098297\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.098054\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.098158\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.098124\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.098124\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.097881\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.097777\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.097742\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.097707\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.097291\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[23:07:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.097256\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.097256\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.097187\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.097118\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09691\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.096771\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.096806\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.096806\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.096459\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.096424\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.096563\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.096597\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.096112\u001b[0m\n",
      "\u001b[34m[23:07:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.096147\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.096112\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 30 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.096147\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.096216\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.096181\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 28 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.095869\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.0958\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.09573\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.095765\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.095592\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.095557\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 26 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.095557\u001b[0m\n",
      "\u001b[34m[23:07:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 30 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.095106\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.095106\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 24 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.095279\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.094828\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 22 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.094863\u001b[0m\n",
      "\u001b[34m[23:07:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.094759\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-15 23:07:47 Completed - Training job completed\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='RED'>Deploy the model</FONT>\n",
    "\n",
    "#### In this step, you will deploy the trained model to an endpoint, reformat then load the CSV data, then run the model to create predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To deploy the model on a server and create an endpoint that you can access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict whether customers in the test data enrolled for the bank product or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this step, you will evaluate the performance and accuracy of the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.5%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    90% (10785)    35% (151)\n",
      "Purchase        10% (1143)     65% (278) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <FONT color='RED'>Terminate your resources</FONT>\n",
    "#### Important: Terminating resources that are not actively being used reduces costs and is a best practice. Not terminating your resources will result in a charge.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To delete the Amazon SageMaker endpoint and the objects in your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'E185B77128F00795',\n",
       "   'HostId': '/qs/szBoKc+HlzfMhnpaWgKDCzUDv9pf8yeYNKalFbvGBziv77PZaQsZQWXDlsvtlh4tvG3hA3o=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': '/qs/szBoKc+HlzfMhnpaWgKDCzUDv9pf8yeYNKalFbvGBziv77PZaQsZQWXDlsvtlh4tvG3hA3o=',\n",
       "    'x-amz-request-id': 'E185B77128F00795',\n",
       "    'date': 'Thu, 15 Oct 2020 23:32:48 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'sagemaker/DEMO-xgboost-dm/train/train.csv'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-10-15-23-04-44-339/output/model.tar.gz'}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
